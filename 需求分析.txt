Hadoop分布式集群一键部署系统需求文档
1 项目概述
1.1 项目背景
　　　随着大数据技术的发展，Hadoop已成为企业级大数据平台的核心组件。然而，Hadoop集群的部署配置过程复杂且容易出错，涉及多台服务器的环境配置、网络设置、软件安装等多个环节，涉及大量命令行交互和跨节点同步工作，不仅耗时，且对初学者和技术人员都构成了较高的技术门槛，易因配置失误导致集群部署失败。
1.2 项目目标
　　　开发一款基于JavaFX图形界面的企业级一键部署工具，用户已具备3台虚拟机，工具通过远程连接虚拟机执行操作。支持Hadoop集群“一键部署”与“自定义部署”两种模式，涵盖“远程连接→环境配置→Hadoop安装→集群配置→验证验收”全流程，让用户像安装普通桌面软件一样，30分钟内完成Hadoop分布式集群部署，大幅降低Hadoop学习和使用门槛。
1.3 核心价值
　　　? 降门槛：通过图形化向导替代命令行操作，消除技术壁垒，降低Hadoop集群部署门槛；
　　　? 提效率：将部署周期从数小时压缩至30分钟内，减少人工操作成本；
　　　? 标准化：固化集群部署流程和配置参数，避免人工配置差异导致的集群不稳定问题；
　　　? 易验证：自动执行服务状态检查验收操作，确保集群部署即可用。
　　　? 灵活性：支持一键部署（默认节点角色）与自定义部署（灵活配置角色），适配不同用户需求。
2. 功能需求
2.1 图形用户界面（JavaFX）
2.1.1 部署向导模块
　　　采用分步式向导设计，明确划分“远程连接配置→部署模式选择→集群参数配置→部署进度→验收报告”5个核心步骤，步骤间逻辑清晰，支持“上一步/下一步/取消”操作；
　　　部署进度页实时展示当前执行步骤（“配置SSH免密登录”）、整体进度条（百分比）；
　　　异常场景（如VMware服务未启动、网络中断）提供弹窗提示，提示内容需使用用户易懂的自然语言，避免技术术语堆砌。
2.1.2 远程连接配置界面
虚拟机连接配置区：
　　　支持输入3台虚拟机的IP地址（分别对应虚拟机1、虚拟机2、虚拟机3），输入框提供格式校验（如IP地址合法性校验）；
　　　支持输入3台虚拟机的统一用户名、统一密码，提供密码隐藏/显示切换功能；
　　　提供“测试连接”按钮，点击后批量验证与3台虚拟机的SSH连接可用性，显示每台虚拟机的连接状态（成功/失败）；
　　　连接失败时，提示具体故障节点（如“虚拟机1（192.168.10.101）连接失败”）及可能原因（如网络不通、用户名密码错误、SSH 服务未启动）。
2.1.3 部署模式选择界面
　　　提供两种部署模式供用户选择，默认选中 “一键部署”：
　　　一键部署：自动分配节点角色（虚拟机1：NameNode；虚拟机2：ResourceManager；虚拟机3：SecondaryNameNode），无需用户额外配置；
　　　自定义部署：用户可通过下拉菜单为每台虚拟机分配角色（可选角色：NameNode、ResourceManager、SecondaryNameNode），支持单选或多选（DataNode为默认必选角色，确保数据存储能力）。
2.1.4 集群参数配置界面
网络配置区：
　　　自动读取虚拟机IP配置，展示3台虚拟机的IP、主机名映射关系（默认主机名：hadoop101、hadoop102、hadoop103，支持用户修改主机名）；
　　　自动生成/etc/hosts配置内容，预览后同步至3台虚拟机，确保节点间主机名互通。
系统参数区：
　　　普通用户名配置：默认创建user用户（支持自定义用户名），密码默认“123456”（支持自定义）；
　　　自动配置该普通用户免密sudo权限（修改/etc/sudoers文件，添加“[用户名] ALL=(ALL) NOPASSWD:ALL”）；
　　　目录权限配置：默认在3台虚拟机/opt目录下创建module、software文件夹，自动修改所属主与所属组为普通用户。
　　　
Hadoop 组件配置区：
　　　JDK配置：
　　　版本：默认JDK1.8.0_212（支持用户选择1.8.x系列）；
　　　安装目录：默认/opt/module/jdk1.8.0_212（不可修改，确保环境变量统一）；
　　　Hadoop 配置：
　　　版本：默认Hadoop 3.1.3（支持用户选择其他版本）；
　　　安装目录：默认/opt/module/hadoop-3.1.3（不可修改）；
　　　核心参数：HDFS块大小默认128MB（支持用户在64MB-256MB 范围内调整），YARN总内存默认2GB（支持根据虚拟机内存手动调整）；
　　　自定义部署模式下，同步显示用户已分配的节点角色，供参数配置参考。
2.1.5 集群管理界面
　　　部署完成后自动跳转至集群管理界面，展示3节点拓扑图（图形化标注每台虚拟机的IP、主机名及分配的角色）；实时监控节点状态：
　　　基础状态：远程连接状态（在线/离线）；
　　　资源状态：CPU使用率、内存使用率（每30秒刷新一次，通过SSH执行“top”命令解析）；
　　　服务状态：已部署的Hadoop服务进程运行情况（通过“jps”命令检测）；
　　　集成快捷操作按钮：
　　　批量操作：启动集群、停止集群、重启集群、查看集群状态（执行jpsall脚本）；
　　　单节点操作：启动节点服务、停止节点服务、查看节点日志；
　　　WebUI访问：提供“NameNode（9870 端口）”“ResourceManager（8088端口）”“历史服务器（19888端口）”快捷链接，点击自动调用默认浏览器打开对应界面。
2.2 远程集群部署核心功能
2.2.1 基础环境预处理
　　　SSH免密登录配置：
　　　在用户指定的主部署节点（一键部署模式下默认虚拟机1，自定义部署模式下默认NameNode所在节点）生成SSH密钥对（rsa格式）；
　　　通过远程命令执行，将公钥自动分发至3台虚拟机，确保主部署节点可免密登录所有节点，节点间互访免密。
　　　系统依赖安装：
　　　批量在3台虚拟机安装epel-release、net-tools、vim、ntp、openssl等依赖包；
　　　关闭3台虚拟机的firewalld防火墙及SELinux，禁用不必要的系统服务（如postfix），优化集群运行环境；
　　　卸载虚拟机自带的JDK（若存在），避免版本冲突。
　　　时间同步配置：
　　　以主部署节点为时间服务器，配置NTP服务；
　　　其他节点配置NTP客户端，自动同步主节点时间，确保集群节点时间偏差≤1秒。
2.2.2 组件安装与配置
　　　JDK安装：
　　　用户上传自己的jdk版本，在主部署节点解压安装包至默认目录，配置JAVA_HOME环境变量（写入/etc/profile.d/my_env.sh）；
　　　通过xsync脚本将JDK目录及环境变量文件分发至另外2台虚拟机，执行“source /etc/profile”使配置生效；
　　　批量验证JDK安装结果（执行“java -version”），确保3台节点版本一致。
　　　Hadoop安装：
　　　用户上传自己的Hadoop版本，在主部署节点解压安装包至默认目录，配置HADOOP_HOME环境变量（写入/etc/profile.d/my_env.sh）；
　　　通过xsync脚本将Hadoop目录及环境变量文件分发至另外2台虚拟机，执行“source /etc/profile”使配置生效；
　　　批量验证Hadoop安装结果（执行“hadoop version”），确保3台节点版本一致。
2.2.3 配置文件生成与分发
　　　配置文件生成：
　　　基于 FreeMarker 模板引擎，根据用户选择的部署模式、节点角色及配置参数，动态生成 Hadoop 核心配置文件：
　　　hadoop-env.sh：配置 JAVA_HOME、Hadoop 进程内存参数；
　　　core-site.xml：配置 HDFS 默认文件系统（指向 NameNode 所在节点的 8020 端口）、临时文件目录；
　　　hdfs-site.xml：配置 HDFS 副本数（默认 2）、NameNode/DataNode 数据存储目录；
　　　mapred-site.xml：配置 MapReduce 框架为 YARN、历史服务器地址；
　　　yarn-site.xml：配置 ResourceManager 地址（指向 ResourceManager 所在节点）、NodeManager 资源配置；
　　　workers：写入 3 台虚拟机的主机名，指定 DataNode 节点列表。
　　　配置文件分发：
　　　通过 xsync 脚本将生成的所有配置文件批量分发至 3 台虚拟机的 $HADOOP_HOME/etc/hadoop 目录；
2.2.4 集群初始化与启动
　　　HDFS格式化：
　　　在 NameNode 所在节点（一键部署模式下为虚拟机 1）执行 “hdfs namenode -format”，格式化前自动检查数据目录是否为空（避免重复格式化）；
　　　格式化完成后，验证 NameNode 数据目录（data/dfs/name）是否生成。
　　　集群启动：
　　　一键部署模式下，按固定顺序启动服务：在 NameNode 节点启动 HDFS（start-dfs.sh），在 ResourceManager 节点启动 YARN（start-yarn.sh），在 NameNode 节点启动历史服务器（mapred --daemon start historyserver）；
　　　自定义部署模式下，根据用户分配的角色，在对应节点启动相关服务；
　　　启动完成后，通过 jpsall 脚本批量检查各节点进程状态，确保指定角色的服务进程正常运行。
2.3 部署验证与验收
2.3.1 服务状态验证
　　　WebUI 访问验证：
　　　NameNode：访问 “http://[NameNode 节点 IP]:9870”，检查 HDFS Summary 中 DataNode 数量是否为 3；
　　　ResourceManager：访问 “http://[ResourceManager 节点 IP]:8088”，检查 “Nodes” 数量是否为 3；
　　　历史服务器：访问 “http://[NameNode 节点 IP]:19888”，确认页面可正常打开；
　　　界面提供对应 WebUI 的快捷访问链接，点击自动调用默认浏览器。
　　　
　　　命令行验证：
　　　执行 “hdfs dfsadmin -report”，查看 DataNode 状态（需显示 3 个节点，状态为 “Live”）；
　　　执行 “yarn node -list”，查看 NodeManager 状态（需显示 3 个节点，状态为 “RUNNING”）；
　　　执行 WordCount 功能测试：创建 HDFS 测试目录，上传测试文件，运行示例程序，验证输出结果正确性。密钥生成：在 Hadoop101节点（user用户）执行“ssh-keygen -t rsa”，生成id_rsa（私钥）与id_rsa.pub（公钥）；
2.3.2 验收报告生成
　　　报告内容包含：
　　　连接信息：3 台虚拟机的 IP、主机名、连接状态；
　　　部署信息：部署模式、各节点角色分配、JDK/Hadoop 版本、部署耗时；
　　　服务状态：各节点 Hadoop 服务进程运行情况（运行 / 未运行）；
　　　测试结果：WebUI 访问地址、功能测试（WordCount）执行结果；
　　　支持导出报告（格式：TXT），用户可自定义保存路径。
2.4 脚本自动生成与管理
　　　自动生成常用脚本（路径：/home/[普通用户名]/bin）：
　　　xsync：集群文件分发脚本，支持递归同步目录 / 文件至所有节点；
　　　myhadoop.sh：集群启停脚本，支持 “start”（启动 HDFS+YARN + 历史服务器）、“stop”（停止所有服务）、“restart”（重启集群）操作；
　　　jpsall：批量查看 3 台节点 Java 进程的脚本；
　　　脚本权限配置：自动赋予脚本执行权限（chmod +x），并同步至 3 台虚拟机，支持用户通过工具界面调用脚本执行。
3. 非功能需求
3.1 性能需求
　　　部署时间：在满足硬件要求（虚拟机单节点 CPU≥2 核、内存≥4GB，宿主机网络稳定）的环境下，总耗时≤30 分钟；
　　　资源占用：部署过程中宿主机 CPU 使用率≤80%，内存占用≤70%，不影响其他应用运行；
　　　操作响应：界面按钮点击、页面切换响应时间≤1 秒，远程命令执行结果反馈时间≤3 秒；
　　　文件分发：单文件（≤500MB）分发至 3 台节点的总时间≤5 分钟（取决于网络带宽）。
3.2 兼容性需求
　　　宿主机操作系统：
　　　Windows：Windows 10/11（64 位）；
　　　Linux：CentOS 7（64 位）；
　　　VMware 版本：VMware Workstation Pro 17.x；
　　　虚拟机操作系统：CentOS 7 64 位；
　　　软件版本：
　　　JDK：1.8.0_200 及以上；
　　　Hadoop：2.7.7、3.1.3、3.3.4（稳定版）；
　　　浏览器：Chrome 80+、Firefox 75+、Edge 80+（用于 WebUI 访问）。
3.3 可靠性需求
　　　部署成功率：在满足环境要求的情况下，成功率≥95%；
　　　异常处理：
　　网络中断：文件下载或分发过程中中断，支持断点续传（最多自动重试 3 次）；
　　服务启动失败：自动检查日志，提示可能原因（如配置文件错误），提供重试启动选项；
　　连接断开：部署过程中虚拟机连接断开，提示用户重新测试连接，恢复后可从断点继续部署；
　　　数据一致性：确保三节点的配置文件、软件版本、目录权限完全一致，避免因差异导致集群异常。
3.4 安全性需求
　　　敏感信息处理：用户输入的虚拟机密码在内存中加密存储，日志中自动脱敏（替换为 “***”）；
　　　权限控制：所有远程操作通过普通用户执行（避免 root 用户直接操作风险），仅必要操作（如修改 sudoers 文件）临时使用 root 权限；
　　　文件校验：自动校验 JDK、Hadoop 安装包及配置文件的 MD5 值，防止文件损坏或篡改；
　　　日志安全：部署日志仅本地存储，包含操作时间、步骤、结果，不泄露敏感信息（如密码）。
3.5 易用性需求
　　　界面引导：提供tooltip提示（如“IP需与VMnet8网段一致”），关键步骤提供帮助文档入口；
　　　错误提示：使用自然语言描述错误，避免技术术语堆砌；
　　　操作简化：无需用户手动执行命令，所有步骤通过点击完成，符合一键部署定位。
4. 技术架构
4.1 前端层（JavaFX 17+）
　　　界面构建：使用 JavaFX Scene Builder 设计分步向导、配置管理、集群管理界面，采用 MVC 模式分离视图与业务逻辑；
　　　界面风格：适配 Windows/Linux 系统原生风格，确保用户操作习惯一致性；
　　　交互组件：集成进度条、日志文本框、拓扑图控件、下拉菜单、按钮组等组件，支持实时数据刷新与用户交互。
4.2 核心服务层
模块	技术选型	功能说明
远程连接模块	JSch	实现与虚拟机的SSH连接，执行远程命令、文件上传/下载
配置生成模块	FreeMarker	基于模板动态生成 Hadoop 核心配置文件、Shell 脚本
进度管理模块	观察者模式	实时监听部署步骤进度，更新界面进度条与日志
脚本生成与
执行模块	Shell脚本模板、JSch	自动生 xsync、myhadoop.sh、jpsall脚本，远程执行并返回结果
网络检测模块	Java NetworkInterface、Ping命令	检测虚拟机IP可达性、SSH 服务状态
异常处理模块	自定义异常类	捕获并分类处理部署过程中的各类异常（连接异常、执行异常）
4.3 数据存储层
　　　配置文件：使用 JSON 格式保存用户配置（如虚拟机 IP、部署模式、组件版本），默认路径：~/.hads/config.json；
　　　日志文件：采用滚动日志策略（log4j2），单个文件最大 100MB，保留最近 10 个文件，默认路径：~/.hads/logs/；
　　　缓存数据：临时存储下载的安装包、离线资源包，默认路径：~/.hads/cache/，支持手动清理。